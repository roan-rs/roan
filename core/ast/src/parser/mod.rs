mod expressions;
mod statements;

use crate::{
    lexer::token::{Token, TokenKind},
    Ast,
};
use anyhow::Result;
use tracing::debug;
use roan_error::error::PulseError::ExpectedToken;

#[derive(Debug, PartialEq, Eq)]
pub enum ParseContext {
    Normal,
    IfCondition,
    WhileCondition,
}

/// A parser that converts a list of tokens into an Abstract Syntax Tree (AST).
///
/// This struct takes tokens generated by the lexer and produces an AST,
/// which represents the structure of the source code in a tree format.
#[derive(Debug)]
pub struct Parser {
    /// A list of tokens to be parsed.
    pub tokens: Vec<Token>,
    /// The current index of the token being processed.
    pub current: usize,
    /// The current context stack for parsing.
    pub context_stack: Vec<ParseContext>,
}

impl Parser {
    /// Creates a new `Parser` instance with a set of tokens to parse.
    ///
    /// # Arguments
    /// * `tokens` - The list of tokens generated by the lexer.
    ///
    /// # Returns
    /// * A new `Parser` instance ready to parse the tokens.
    pub fn new(tokens: Vec<Token>) -> Self {
        Self {
            tokens,
            current: 0,
            context_stack: vec![ParseContext::Normal],
        }
    }

    /// Returns a reference to the current parser context.
    ///
    /// # Panics
    ///
    /// This function will panic if the `context_stack` is empty. However, this condition
    /// should never happen because the context stack should always have at least one context.
    pub fn current_context(&self) -> &ParseContext {
        self.context_stack
            .last()
            .expect("Parser context stack should never be empty")
    }

    /// Pushes a new context onto the context stack.
    ///
    /// # Parameters
    ///
    /// - `context`: The `ParseContext` to be pushed onto the stack.
    pub fn push_context(&mut self, context: ParseContext) {
        debug!("Pushing context: {:?}", context);
        self.context_stack.push(context);
    }

    /// Pops the current context off the context stack.
    pub fn pop_context(&mut self) {
        debug!("Popping context: {:?}", self.current_context());
        self.context_stack.pop();
    }

    /// Checks if the current context matches a given context.
    ///
    /// # Parameters
    ///
    /// - `context`: A reference to a `ParseContext` to compare with the current context.
    ///
    /// # Returns
    ///
    /// `true` if the current context is equal to the given context, `false` otherwise.
    pub fn is_context(&self, context: &ParseContext) -> bool {
        debug!(
            "Checking context: {:?} == {:?}",
            self.current_context(),
            context
        );
        self.current_context() == context
    }
}

impl Parser {
    /// Parses the list of tokens and constructs an AST.
    ///
    /// This method will continue parsing tokens until the end of the token stream
    /// (or an EOF token) is encountered. Each token sequence is turned into a statement
    /// and added to the AST.
    ///
    /// # Returns
    /// * `Ok(Ast)` - If the parsing is successful and an AST is created.
    /// * `Err` - If an error occurs during parsing.
    pub fn parse(&mut self) -> Result<Ast> {
        let mut ast = Ast::new();

        // Parse tokens into statements until EOF is reached
        while !self.is_eof() {
            // Parse a statement, if successful, add it to the AST
            let stmt = self.parse_stmt()?;

            if let Some(stmt) = stmt {
                ast.stmts.push(stmt);
            }
        }

        Ok(ast)
    }

    /// Consumes the current token and advances to the next token in the stream.
    ///
    /// # Returns
    /// * The previous token that was consumed.
    pub fn consume(&mut self) -> Token {
        if !self.is_eof() {
            self.current += 1;
        }

        self.previous()
    }

    /// Retrieves the previous token.
    ///
    /// # Panics
    /// This function will panic if there are no previous tokens.
    pub fn previous(&self) -> Token {
        assert!(self.current > 0);
        self.tokens[self.current - 1].clone()
    }

    /// Peeks at the current token without consuming it.
    ///
    /// # Returns
    /// * A copy of the current token.
    pub fn peek(&self) -> Token {
        self.tokens[self.current].clone()
    }

    /// Peeks at the next token without consuming the current one.
    ///
    /// # Returns
    /// * A copy of the next token.
    pub fn peek_next(&self) -> Token {
        self.tokens[self.current + 1].clone()
    }

    /// Checks if the current token is the end of file (EOF).
    ///
    /// # Returns
    /// * `true` if the current token is EOF, otherwise `false`.
    pub fn is_eof(&self) -> bool {
        self.current >= self.tokens.len() || self.peek().kind == TokenKind::EOF
    }

    /// Consumes the current token if it matches the specified `TokenKind`.
    ///
    /// # Arguments
    /// * `kind` - The kind of token to check.
    pub fn possible_check(&mut self, kind: TokenKind) {
        if self.peek().kind == kind {
            self.consume();
        }
    }

    /// Expects the current token to be of a specific `TokenKind` and consumes it.
    ///
    /// If the token matches the expected kind, it is consumed and returned.
    /// If not, an error is raised indicating the expected token.
    ///
    /// # Arguments
    /// * `kind` - The expected kind of the current token.
    ///
    /// # Returns
    /// * `Ok(Token)` - The token that was consumed.
    /// * `Err` - An error if the current token is not of the expected kind.
    pub fn expect(&mut self, kind: TokenKind) -> Result<Token> {
        let token = self.peek();

        debug!("Expected token: {:?}, found: {:?}", kind, token.kind);
        if token.kind == kind {
            Ok(self.consume())
        } else {
            Err(ExpectedToken(
                kind.to_string(),
                format!("Expected token of kind: {}", kind),
                token.span.clone(),
            )
            .into())
        }
    }
}
