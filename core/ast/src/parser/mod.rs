mod expressions;
mod statements;

use crate::{
    lexer::token::{Token, TokenKind},
    Ast,
};
use anyhow::Result;
use log::debug;
use roan_error::error::PulseError::ExpectedToken;

/// A parser that converts a list of tokens into an Abstract Syntax Tree (AST).
///
/// This struct takes tokens generated by the lexer and produces an AST,
/// which represents the structure of the source code in a tree format.
#[derive(Debug)]
pub struct Parser {
    /// A list of tokens to be parsed.
    pub tokens: Vec<Token>,
    /// The current index of the token being processed.
    pub current: usize,
}

impl Parser {
    /// Creates a new `Parser` instance with a set of tokens to parse.
    ///
    /// # Arguments
    /// * `tokens` - The list of tokens generated by the lexer.
    ///
    /// # Returns
    /// * A new `Parser` instance ready to parse the tokens.
    pub fn new(tokens: Vec<Token>) -> Self {
        Self { tokens, current: 0 }
    }
}

impl Parser {
    /// Parses the list of tokens and constructs an AST.
    ///
    /// This method will continue parsing tokens until the end of the token stream
    /// (or an EOF token) is encountered. Each token sequence is turned into a statement
    /// and added to the AST.
    ///
    /// # Returns
    /// * `Ok(Ast)` - If the parsing is successful and an AST is created.
    /// * `Err` - If an error occurs during parsing.
    pub fn parse(&mut self) -> Result<Ast> {
        let mut ast = Ast::new();

        // Parse tokens into statements until EOF is reached
        while !self.is_eof() {
            // Parse a statement, if successful, add it to the AST
            let stmt = self.parse_stmt()?;

            if let Some(stmt) = stmt {
                ast.stmts.push(stmt);
            }
        }

        Ok(ast)
    }

    /// Consumes the current token and advances to the next token in the stream.
    ///
    /// # Returns
    /// * The previous token that was consumed.
    pub fn consume(&mut self) -> Token {
        if !self.is_eof() {
            self.current += 1;
        }

        self.previous()
    }

    /// Retrieves the previous token.
    ///
    /// # Panics
    /// This function will panic if there are no previous tokens.
    pub fn previous(&self) -> Token {
        assert!(self.current > 0);
        self.tokens[self.current - 1].clone()
    }

    /// Peeks at the current token without consuming it.
    ///
    /// # Returns
    /// * A copy of the current token.
    pub fn peek(&self) -> Token {
        self.tokens[self.current].clone()
    }

    /// Peeks at the next token without consuming the current one.
    ///
    /// # Returns
    /// * A copy of the next token.
    pub fn peek_next(&self) -> Token {
        self.tokens[self.current + 1].clone()
    }

    /// Checks if the current token is the end of file (EOF).
    ///
    /// # Returns
    /// * `true` if the current token is EOF, otherwise `false`.
    pub fn is_eof(&self) -> bool {
        self.current >= self.tokens.len() || self.peek().kind == TokenKind::EOF
    }

    /// Consumes the current token if it matches the specified `TokenKind`.
    ///
    /// # Arguments
    /// * `kind` - The kind of token to check.
    pub fn possible_check(&mut self, kind: TokenKind) {
        if self.peek().kind == kind {
            self.consume();
        }
    }

    /// Expects the current token to be of a specific `TokenKind` and consumes it.
    ///
    /// If the token matches the expected kind, it is consumed and returned.
    /// If not, an error is raised indicating the expected token.
    ///
    /// # Arguments
    /// * `kind` - The expected kind of the current token.
    ///
    /// # Returns
    /// * `Ok(Token)` - The token that was consumed.
    /// * `Err` - An error if the current token is not of the expected kind.
    pub fn expect(&mut self, kind: TokenKind) -> Result<Token> {
        let token = self.peek();

        debug!("Expected token: {:?}, found: {:?}", kind, token.kind);
        if token.kind == kind {
            Ok(self.consume())
        } else {
            Err(ExpectedToken(
                kind.to_string(),
                format!("Expected token of kind: {}", kind),
                token.span.clone(),
            )
            .into())
        }
    }
}
